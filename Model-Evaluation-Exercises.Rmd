---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}
#https://www.r-bloggers.com/model-evaluation-exercises-1/

#a. What is the precision of the model?
#b. What is the recall of the model?
3/5
3/7

#a. Number of true positives?
#b. Number of false negatives?
#c. Number of true negatives?
#d. Number of false positives?
100
24
94
23

sum(100,24,23,94)

#is to use the formula (TN+TP)/N. What is the accuracy of the model?
(94+100)/241

#Quick way to gauge the error rate is to use the formula (FP/FN)/N. What is the overall error rate?
(23+24)/241

#Sensitivity is defined as TP/(TP+FN). Specificity is defined as TN/(TN+FP). Using that information, answer the following questions
#a.What is the sensitivity of the model?
#b.What is the specificity of the model?
100/(100+24)
94/(94+23)

#There are usually two type of errors, false positive and false negative. False negative error rate is defined as FN/(TP+FN). False positive error rate is defined as FP/(TN+FP). Now answer the following questions:
#a. What is the False negative error?
#b. What is the False positive error?
24/(100+24)
23/(94+23)

#Now suppose this is a model like that was used to identify iphones from androids in a video(Q1).
#a. What is the precision?
#b. What is the recall? Hint: Recall is the same as sensitivity.
100/(100+23)
100/(100+24)

#Go ahead and run the code below. You may run line by line to see what is happening. In brief, we are loading the housing data, changing the Cont variable to binary class, splitting the data into Train and Test set, Building a model, predicting and comparing actual Cont value in the Test set with predicted value in pred.
if(!require(caTools)){
    install.packages("caTools")
}
library(caTools)
if(!require(MASS)){
    install.packages("MASS")
}
library(MASS)
attach(housing)
housing$Cont = ifelse(housing$Cont == "High", 1,0)
spl = sample.split(housing$Cont, SplitRatio = 0.7)
Train = housing[spl==TRUE,]
Test = housing[spl==FALSE,]
model <- glm(Cont~., family = binomial, data = Train)
pred = predict(model, newdata = Test)
table(Test$Cont, pred>0.5)

#Using the confusion matrix output from your last code, answer the following questions.
#a) What is the Precision?
#b) What is the recall?
4/(4+5)
4/(4+7)

#Using the confusion matrix, answer the follwing questions
#c) What is the accuracy of the model?
#d) What is the overall error rate?    
(4+6)/22
(5+7)/22

    
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).
